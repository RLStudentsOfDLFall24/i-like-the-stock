params:
  hidden_size: 32
  dropout: 0.2
  num_layers: 2
  num_outputs: 3

trainer:
  global_to_target_split: 0.8
  batch_size: 32
  seq_len: 256
  epochs: 100
  lr: 5.e-6
  fine_tune_lr_ratio: 0.08
  optimizer:
    name: "adam"
    config:
      eps: 1.e-8
      betas: [0.9, 0.99]
      weight_decay: 1.e-3
  scheduler:
    name: 'plateau'
  criterion:
    name: "ce"
