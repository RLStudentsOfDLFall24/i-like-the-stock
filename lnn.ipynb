{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset._dataset_utils import create_datasets\n",
    "\n",
    "\n",
    "ds_names = ['atnf', 'biaf', 'bivi', 'cycc', 'vtak']\n",
    "\n",
    "SEQ_LEN = 30\n",
    "LOG_SPLITS = False\n",
    "FIXED_SCALING = [(7, 3000.), (8, 12.), (9, 31.)]\n",
    "ROOT = './data/clean'\n",
    "\n",
    "datasets = { x: create_datasets(x, ROOT, FIXED_SCALING, LOG_SPLITS) for x in ds_names }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 22])\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-3\n",
    "BETAS = (0.9, 0.999)\n",
    "EPS = 1e-8\n",
    "WEIGHT_DECAY=1e-5\n",
    "\n",
    "GAMMA = 0.5\n",
    "STEP_SIZE = 0.1\n",
    "MILESTONES = [5, 10, 15]\n",
    "MIN_LR = 1e-10\n",
    "CRITERION_GAMMA=2.0\n",
    "\n",
    "OPTIMIZER = 'adam' # 'adam' or 'sgd'\n",
    "SCHEDULER = 'step' # 'plateau', 'step', or 'multi'\n",
    "CRITERION = 'ce'   # 'ce' or 'cb_focal'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_SIZE = 32\n",
    "\n",
    "EPOCHS = 40\n",
    "\n",
    "data='atnf'\n",
    "\n",
    "print(datasets[data][0][0][0].shape)\n",
    "\n",
    "input_size = datasets[data][0][0][0].shape[1]\n",
    "train_label_ct = datasets[data][0].target_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from src.cbfocal_loss import FocalLoss\n",
    "from src.models.abstract_model import AbstractModel\n",
    "\n",
    "\n",
    "def get_optimizer(type: str, model: AbstractModel, lr, **kwargs):\n",
    "  match type:\n",
    "    case 'adam':\n",
    "      return torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        **kwargs,\n",
    "      )\n",
    "    case 'sgd':\n",
    "      return torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        **kwargs,\n",
    "      )\n",
    "    case _:\n",
    "      raise ValueError(f'Unknown optimizer: {type}')\n",
    "  \n",
    "\n",
    "def get_scheduler(type: str, optimizer: torch.optim.Optimizer, **kwargs):\n",
    "  match type:\n",
    "    case 'plateau':\n",
    "      return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, **kwargs)\n",
    "    case 'step':\n",
    "      return torch.optim.lr_scheduler.StepLR(optimizer, **kwargs)\n",
    "    case 'multi':\n",
    "      return torch.optim.lr_scheduler.MultiStepLR(optimizer, **kwargs)\n",
    "    case _:\n",
    "      raise ValueError(f'Unknown scheduler: {type}')\n",
    "    \n",
    "\n",
    "def get_criterion(type: str, train_label_ct: Optional[torch.Tensor] = None, device='cpu', **kwargs):\n",
    "  match type:\n",
    "    case 'ce':\n",
    "      weight = None\n",
    "      if train_label_ct is not None:\n",
    "        weight = train_label_ct.max() / train_label_ct\n",
    "        weight = weight / weight.sum()\n",
    "        weight = weight.to(device)\n",
    "\n",
    "      return torch.nn.CrossEntropyLoss(\n",
    "        weight=weight,\n",
    "      )\n",
    "    case 'cb_focal':\n",
    "      return FocalLoss(\n",
    "        class_counts=train_label_ct.to(device),\n",
    "        **kwargs,\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models.lnn import LNN\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "model = LNN(BATCH_SIZE, input_size, HIDDEN_SIZE, 3, n_layers=6, activation='leaky_relu').to(device)\n",
    "optimizer = get_optimizer(OPTIMIZER, model, LR, betas=BETAS, eps=EPS)\n",
    "scheduler = get_scheduler(SCHEDULER, optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "criterion = get_criterion(CRITERION, train_label_ct, device)\n",
    "\n",
    "ds_train, ds_valid, ds_test = datasets[data]\n",
    "\n",
    "train_loader, valid_loader, test_loader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True), DataLoader(ds_valid, batch_size=BATCH_SIZE, shuffle=False), DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: AbstractModel,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.CrossEntropyLoss | FocalLoss,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    writer: SummaryWriter = None,\n",
    "  ):\n",
    "  model.train()\n",
    "\n",
    "  losses = np.zeros(len(dataloader))\n",
    "\n",
    "  for idx, data in enumerate(dataloader):\n",
    "    x = data[0].to(device)\n",
    "    y = data[1].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits: torch.Tensor = model(x)\n",
    "\n",
    "    if len(logits.shape) == 1:\n",
    "      logits = logits.unsqueeze(0)\n",
    "\n",
    "    loss = criterion(logits, y)\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if writer is not None:\n",
    "      for l, (name, param) in enumerate(model.named_parameters()):\n",
    "        if param.grad is not None:\n",
    "          writer.add_scalar(f'Gradients/{l:02}_{name}', param.grad.norm().item(), epoch * len(dataloader) + idx)\n",
    "\n",
    "    losses[idx] = loss.item()\n",
    "\n",
    "  return losses.sum(), losses.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: AbstractModel,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: torch.optim.Optimizer,\n",
    "    device: torch.device = 'cpu',\n",
    "):\n",
    "  losses = np.zeros(len(dataloader))\n",
    "  accuracies = np.zeros(len(dataloader))\n",
    "\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with torch.no_grad():\n",
    "    for idx, data in enumerate(dataloader):\n",
    "      x = data[0].to(device)\n",
    "      y = data[1].to(device)\n",
    "\n",
    "      logits = model(x)\n",
    "\n",
    "      preds = torch.argmax(logits, dim=1)\n",
    "      all_preds.append(preds)\n",
    "      all_labels.append(y)\n",
    "\n",
    "      losses[idx] = criterion(logits, y).item()\n",
    "      accuracies[idx] = torch.sum(torch.argmax(logits, dim=1) == y).item() / y.shape[0]\n",
    "\n",
    "  all_preds = torch.cat(all_preds).cpu()\n",
    "  all_labels = torch.cat(all_labels).cpu()\n",
    "\n",
    "  classes, counts = torch.unique(all_preds, return_counts=True)\n",
    "  pred_dist = torch.zeros(3)\n",
    "  pred_dist[classes] = counts / counts.sum()\n",
    "\n",
    "  f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "  return losses.sum(), losses.mean(), accuracies.mean(), f1_weighted, pred_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 1 | Train: nan | Valid nan | V_Pred Dist: C0 1.000 - C1 0.000 - C2 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[246], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#scheduler.step(train_loss)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 13\u001b[0m _, valid_loss_avg, _, _, v_pred_dist \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m train_losses[epoch] \u001b[38;5;241m=\u001b[39m train_loss_avg\n\u001b[0;32m     16\u001b[0m valid_losses[epoch] \u001b[38;5;241m=\u001b[39m valid_loss_avg\n",
      "Cell \u001b[1;32mIn[245], line 20\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataloader, criterion, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 20\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mappend(preds)\n",
      "File \u001b[1;32mc:\\Users\\killy\\.conda\\envs\\dl-group-project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\killy\\.conda\\envs\\dl-group-project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Code\\GATech\\CS7643\\i-like-the-stock\\src\\models\\lnn.py:54\u001b[0m, in \u001b[0;36mLNN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[1;32m---> 54\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fused_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x)\n",
      "File \u001b[1;32md:\\Code\\GATech\\CS7643\\i-like-the-stock\\src\\models\\lnn.py:59\u001b[0m, in \u001b[0;36mLNN.__fused_step\u001b[1;34m(self, data, hidden)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__fused_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: torch\u001b[38;5;241m.\u001b[39mTensor, hidden: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 59\u001b[0m     func_data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m+\u001b[39m hidden \u001b[38;5;241m@\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_weight\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     61\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(func_data)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (hidden \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size \u001b[38;5;241m*\u001b[39m activation \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_constant) \u001b[38;5;241m+\u001b[39m activation)\n",
      "File \u001b[1;32mc:\\Users\\killy\\.conda\\envs\\dl-group-project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = np.zeros(EPOCHS)\n",
    "valid_losses = np.zeros(EPOCHS)\n",
    "writer = SummaryWriter(log_dir=f\"../data/tensorboard/testing\")\n",
    "\n",
    "#pb = tqdm(total=EPOCHS, desc=\"Epochs\")\n",
    "#pb.clear()\n",
    "#pb.reset()\n",
    "for epoch in range(EPOCHS):\n",
    "  train_loss, train_loss_avg = train(model, train_loader, optimizer, criterion, device, epoch, writer=None)\n",
    "  #scheduler.step(train_loss)\n",
    "  scheduler.step()\n",
    "\n",
    "  _, valid_loss_avg, _, _, v_pred_dist = evaluate(model, valid_loader, criterion, device=device)\n",
    "\n",
    "  train_losses[epoch] = train_loss_avg\n",
    "  valid_losses[epoch] = valid_loss_avg\n",
    "\n",
    "  writer.add_scalar('Loss/train', train_loss_avg, epoch)\n",
    "  writer.add_scalar('Loss/valid', valid_loss_avg, epoch)\n",
    "\n",
    "  pred_string = ' - '.join([f'C{ix} {x:.3f}' for ix, x in enumerate(v_pred_dist)])\n",
    "  #pb.set_description(\n",
    "  #  f'E: {epoch + 1} | Train: {train_loss_avg:.4f} | Valid {valid_loss_avg:.4f} | V_Pred Dist: {pred_string}'\n",
    "  #)\n",
    "  #pb.update(1)\n",
    "  print(f'E: {epoch + 1} | Train: {train_loss_avg:.4f} | Valid {valid_loss_avg:.4f} | V_Pred Dist: {pred_string}')\n",
    "  parms = model.parameters()\n",
    "  test = parms\n",
    "\n",
    "test_loss, test_loss_avg, test_acc, test_f1, test_pred_dist = evaluate(\n",
    "    model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Dataset  | 0: Sell | 1: Hold | 2: Buy |\n",
      "|----------|---------|---------|--------|\n",
      "| Test     |    1.00 |    0.00 |   0.00 |\n",
      "|----------|---------|---------|--------|\n",
      "0.5121228448275862\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dataset._dataset_utils import print_target_distribution\n",
    "\n",
    "print_target_distribution([(\"Test\", test_pred_dist)])\n",
    "\n",
    "print(test_acc)\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Valid Loss')\n",
    "# Set y scale between 0.25 and 1.25\n",
    "plt.xlim(0, EPOCHS)\n",
    "plt.ylim(0.0, 2)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-group-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
