mode:
  - train
  - eval

model_types:
  - rnn
  #- transformer
  #- lnn

global_params:
  symbol: "atnf"
  log_splits: False

rnn:
  batch_size: 10
  hidden_size: 32
  seq_len: 30
  dropout: 0.2
  num_layers: 1
  num_outputs: 3

rnn_trainer:
  epochs: 300
  lr: 5.e-6
  optimizer: "adam"
  scheduler: "plateau"
  criterion: "ce"

lnn:
  batch_size: 10
  n_layers: 6
  hidden_size: 32
  epochs: 10
  lr: 5.e-6
  optimizer: "adam"
  scheduler: "plateau"
  criterion: "ce"  # Class Balanced Focal Loss

transformer:
  batch_size: 64
  seq_len: 30
  model_dim: 64
  time_idx:
    - 0
    - 6
    - 7
    - 8
  fc_dim: 1024
  fc_dropout: 0.3
  n_frequencies: 16
  num_encoders: 4
  num_heads: 4
  num_lstm_layers: 2
  lstm_dim: 128

transformer_trainer:
  epochs: 10
  lr: 5.e-6
  optimizer: "adam"
  scheduler: "plateau"
  criterion: "cb_focal"  # Class Balanced Focal Loss
